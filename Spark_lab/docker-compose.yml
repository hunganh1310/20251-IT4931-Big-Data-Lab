version: '3.8'

services:
  # Spark Master
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master port
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./code:/opt/bitnami/spark/code
      - ./scripts:/opt/bitnami/spark/scripts
    networks:
      - spark-network

  # Spark Worker 1
  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./code:/opt/bitnami/spark/code
      - ./scripts:/opt/bitnami/spark/scripts
    networks:
      - spark-network

  # Spark Worker 2
  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-2
    hostname: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./code:/opt/bitnami/spark/code
      - ./scripts:/opt/bitnami/spark/scripts
    networks:
      - spark-network

  # Jupyter Notebook for Spark
  jupyter-spark:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: jupyter-spark
    hostname: jupyter-spark
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8888:8888"  # Jupyter Lab
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/work/data
      - ./code:/home/jovyan/work/code
    depends_on:
      - spark-master
    networks:
      - spark-network

  # Kafka Broker with KRaft mode (no Zookeeper needed)
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: spark-kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      # KRaft mode configuration
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # Cluster configuration
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      
      # KRaft specific
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - spark-network
    restart: unless-stopped

  # Schema Registry for Avro schemas
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: spark-schema-registry
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - spark-network
    restart: unless-stopped

  # Redis (for caching and real-time data)
  redis:
    image: redis:7.2-alpine
    container_name: spark-redis
    hostname: redis
    ports:
      - "6379:6379"
    networks:
      - spark-network

  # PostgreSQL (for structured data)
  postgres:
    image: postgres:15-alpine
    container_name: spark-postgres
    hostname: postgres
    environment:
      POSTGRES_DB: spark_lab
      POSTGRES_USER: spark_user
      POSTGRES_PASSWORD: spark_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge

volumes:
  postgres_data:
  kafka_data:
