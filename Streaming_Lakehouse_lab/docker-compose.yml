version: '3.8'

services:
  # Spark Master
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: streaming-lakehouse-spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master port
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./scripts:/opt/bitnami/spark/scripts
      - ./warehouse:/opt/bitnami/spark/warehouse
    networks:
      - streaming-lakehouse-network

  # Spark Worker 1
  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: streaming-lakehouse-spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./scripts:/opt/bitnami/spark/scripts
      - ./warehouse:/opt/bitnami/spark/warehouse
    networks:
      - streaming-lakehouse-network

  # Spark Worker 2
  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: streaming-lakehouse-spark-worker-2
    hostname: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./scripts:/opt/bitnami/spark/scripts
      - ./warehouse:/opt/bitnami/spark/warehouse
    networks:
      - streaming-lakehouse-network

  # Jupyter Lab
  jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: streaming-lakehouse-jupyter
    hostname: jupyter
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/work/data
      - ./scripts:/home/jovyan/work/scripts
      - ./warehouse:/home/jovyan/work/warehouse
    depends_on:
      - spark-master
    networks:
      - streaming-lakehouse-network

  # Kafka Broker (KRaft mode)
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: streaming-lakehouse-kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - streaming-lakehouse-network
    restart: unless-stopped

  # MinIO (S3-compatible storage for Iceberg)
  minio:
    image: minio/minio:latest
    container_name: streaming-lakehouse-minio
    hostname: minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"  # MinIO API
      - "9001:9001"  # MinIO Console
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - streaming-lakehouse-network
    restart: unless-stopped

networks:
  streaming-lakehouse-network:
    driver: bridge

volumes:
  kafka_data:
  minio_data:

