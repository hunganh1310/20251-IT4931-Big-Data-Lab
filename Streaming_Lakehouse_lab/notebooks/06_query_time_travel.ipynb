{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: Query, Time Travel & Advanced Features\n",
        "\n",
        "## üéØ **Learning Objectives:**\n",
        "- Query Gold tables (real-time + historical)\n",
        "- Use time travel queries\n",
        "- Understand schema evolution v·ªõi streaming\n",
        "- Compare snapshots\n",
        "- Integration patterns\n",
        "\n",
        "## üìö **Key Concepts:**\n",
        "1. **Unified Query**: Real-time v√† historical t·ª´ c√πng tables\n",
        "2. **Time Travel**: Query data t·∫°i b·∫•t k·ª≥ th·ªùi ƒëi·ªÉm n√†o\n",
        "3. **Schema Evolution**: Add/modify columns v·ªõi streaming writes\n",
        "4. **Snapshots**: Version history c·ªßa data\n",
        "5. **Integration**: BI tools, ML models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"QueryTimeTravel\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "GOLD_TABLE_PATH = \"/warehouse/gold/trade_metrics\"\n",
        "\n",
        "print(\"üöÄ Spark Session initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Query Real-time + Historical\n",
        "\n",
        "### Key Point:\n",
        "C√πng table, query c·∫£ real-time v√† historical data!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query Real-time + Historical\n",
        "print(\"üîç Exercise 1: Query Real-time + Historical\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "gold_df = spark.read.parquet(GOLD_TABLE_PATH)\n",
        "\n",
        "print(\"1Ô∏è‚É£ Latest data (real-time):\")\n",
        "gold_df.orderBy(desc(\"window_start\")).show(10)\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ Historical data (last hour):\")\n",
        "from datetime import datetime, timedelta\n",
        "one_hour_ago = datetime.now() - timedelta(hours=1)\n",
        "gold_df.filter(col(\"window_start\") >= one_hour_ago).show()\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£ All-time aggregates:\")\n",
        "gold_df.groupBy(\"symbol\").agg(\n",
        "    avg(\"avg_price\").alias(\"all_time_avg\"),\n",
        "    sum(\"total_volume\").alias(\"all_time_volume\")\n",
        ").show()\n",
        "\n",
        "print(\"\\nüí° Same table, real-time + historical!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Time Travel Queries\n",
        "\n",
        "### With Iceberg:\n",
        "```sql\n",
        "SELECT * FROM gold.trade_metrics \n",
        "VERSION AS OF 17;\n",
        "\n",
        "SELECT * FROM gold.trade_metrics \n",
        "TIMESTAMP AS OF '2025-01-15 10:30:00';\n",
        "```\n",
        "\n",
        "### Note:\n",
        "Full time travel requires Iceberg JAR. Pattern shown here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time Travel Queries\n",
        "print(\"‚è∞ Exercise 2: Time Travel Queries\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üí° With Iceberg, you can query historical versions:\")\n",
        "print(\"\\n1Ô∏è‚É£ Query by version:\")\n",
        "print(\"   spark.sql('SELECT * FROM gold.trade_metrics VERSION AS OF 17')\")\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ Query by timestamp:\")\n",
        "print(\"   spark.sql(\\\"SELECT * FROM gold.trade_metrics TIMESTAMP AS OF '2025-01-15 10:30:00'\\\")\")\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£ List snapshots:\")\n",
        "print(\"   spark.sql('SELECT * FROM gold.trade_metrics.snapshots')\")\n",
        "\n",
        "print(\"\\nüí° Time travel benefits:\")\n",
        "print(\"   ‚úÖ Query data at any point in time\")\n",
        "print(\"   ‚úÖ Compare before/after transformations\")\n",
        "print(\"   ‚úÖ Rollback if needed\")\n",
        "print(\"   ‚úÖ Audit trail\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### ‚úÖ What we learned:\n",
        "1. **Unified Query**: Real-time + historical t·ª´ c√πng tables\n",
        "2. **Time Travel**: Query data t·∫°i b·∫•t k·ª≥ th·ªùi ƒëi·ªÉm\n",
        "3. **Schema Evolution**: Modify schema v·ªõi streaming\n",
        "4. **Snapshots**: Version history\n",
        "5. **Integration**: Ready for BI, ML\n",
        "\n",
        "### üéØ Streaming Lakehouse Advantages:\n",
        "- ‚úÖ Unified storage (Iceberg)\n",
        "- ‚úÖ Unified code (batch + streaming)\n",
        "- ‚úÖ Unified query (real-time + historical)\n",
        "- ‚úÖ Time travel capabilities\n",
        "- ‚úÖ ACID transactions\n",
        "\n",
        "### üöÄ This is the future of data architecture!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
