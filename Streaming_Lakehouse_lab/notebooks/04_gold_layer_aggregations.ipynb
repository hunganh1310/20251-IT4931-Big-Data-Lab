{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Gold Layer - Aggregations & Features\n",
        "\n",
        "## üéØ **Learning Objectives:**\n",
        "- Aggregate Silver data v·ªõi windowed operations\n",
        "- Create real-time metrics (avg price, volume, volatility)\n",
        "- Build feature tables for ML\n",
        "- Write aggregated data to Gold layer\n",
        "- Query Gold tables for analytics\n",
        "\n",
        "## üìö **Key Concepts:**\n",
        "1. **Gold Layer**: Aggregated, feature-rich data\n",
        "2. **Windowed Aggregations**: Time-based aggregations (1-min, 5-min)\n",
        "3. **Real-time Metrics**: Average price, total volume, price volatility\n",
        "4. **Feature Engineering**: Create features for ML models\n",
        "5. **Analytics Ready**: Data ready for BI, ML, dashboards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StreamingLakehouseGold\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "SILVER_TABLE_PATH = \"/warehouse/silver/trades\"\n",
        "GOLD_TABLE_PATH = \"/warehouse/gold/trade_metrics\"\n",
        "\n",
        "print(\"üöÄ Spark Session initialized for Gold Layer!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Windowed Aggregations\n",
        "\n",
        "### Aggregations:\n",
        "- **1-minute windows**: Real-time metrics\n",
        "- **By symbol**: Per-stock aggregations\n",
        "- **Metrics**: avg_price, total_volume, max_price, min_price, price_range\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Windowed Aggregations\n",
        "print(\"üìä Exercise 1: Windowed Aggregations\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Read Silver nh∆∞ stream\n",
        "silver_stream = spark.readStream \\\n",
        "    .format(\"parquet\") \\\n",
        "    .schema(spark.read.parquet(SILVER_TABLE_PATH).schema) \\\n",
        "    .load(SILVER_TABLE_PATH)\n",
        "\n",
        "print(\"1Ô∏è‚É£ Reading Silver stream...\")\n",
        "\n",
        "# Add watermark\n",
        "with_watermark = silver_stream \\\n",
        "    .withWatermark(\"event_timestamp\", \"5 minutes\")\n",
        "\n",
        "print(\"2Ô∏è‚É£ Windowed aggregations (1-minute windows):\")\n",
        "\n",
        "gold_aggregated = with_watermark \\\n",
        "    .groupBy(\n",
        "        window(col(\"event_timestamp\"), \"1 minute\"),\n",
        "        col(\"symbol\")\n",
        "    ) \\\n",
        "    .agg(\n",
        "        avg(\"price\").alias(\"avg_price\"),\n",
        "        max(\"price\").alias(\"max_price\"),\n",
        "        min(\"price\").alias(\"min_price\"),\n",
        "        (max(\"price\") - min(\"price\")).alias(\"price_range\"),\n",
        "        sum(\"volume\").alias(\"total_volume\"),\n",
        "        sum(\"total_value\").alias(\"total_value\"),\n",
        "        count(\"*\").alias(\"trade_count\")\n",
        "    ) \\\n",
        "    .select(\n",
        "        col(\"window.start\").alias(\"window_start\"),\n",
        "        col(\"window.end\").alias(\"window_end\"),\n",
        "        col(\"symbol\"),\n",
        "        col(\"avg_price\"),\n",
        "        col(\"max_price\"),\n",
        "        col(\"min_price\"),\n",
        "        col(\"price_range\"),\n",
        "        col(\"total_volume\"),\n",
        "        col(\"total_value\"),\n",
        "        col(\"trade_count\")\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Aggregations defined!\")\n",
        "gold_aggregated.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Write to Gold Layer\n",
        "\n",
        "### Output Mode: Update\n",
        "- Update mode: Update existing windows\n",
        "- Complete mode: Full window state (alternative)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write to Gold Layer\n",
        "print(\"üíæ Exercise 2: Write to Gold Layer\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "gold_query = gold_aggregated \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .format(\"parquet\") \\\n",
        "    .option(\"path\", GOLD_TABLE_PATH) \\\n",
        "    .option(\"checkpointLocation\", \"/tmp/gold_checkpoint\") \\\n",
        "    .trigger(processingTime='10 seconds') \\\n",
        "    .start()\n",
        "\n",
        "print(\"‚úÖ Gold streaming query started!\")\n",
        "print(f\"   Writing to: {GOLD_TABLE_PATH}\")\n",
        "print(f\"   Output mode: Update\")\n",
        "\n",
        "print(\"\\nüí° Gold layer characteristics:\")\n",
        "print(\"   ‚úÖ Aggregated metrics\")\n",
        "print(\"   ‚úÖ Windowed by time\")\n",
        "print(\"   ‚úÖ Ready for analytics/ML\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Query Gold Data\n",
        "\n",
        "### Use Cases:\n",
        "- Real-time dashboards\n",
        "- Historical analysis\n",
        "- ML feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query Gold Data\n",
        "print(\"üîç Exercise 3: Query Gold Data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "try:\n",
        "    gold_df = spark.read.parquet(GOLD_TABLE_PATH)\n",
        "    \n",
        "    print(f\"‚úÖ Gold data found! Records: {gold_df.count()}\")\n",
        "    \n",
        "    print(\"\\n1Ô∏è‚É£ Latest metrics by symbol:\")\n",
        "    gold_df.orderBy(desc(\"window_start\")).show(10, truncate=False)\n",
        "    \n",
        "    print(\"\\n2Ô∏è‚É£ Average price by symbol:\")\n",
        "    gold_df.groupBy(\"symbol\").agg(avg(\"avg_price\").alias(\"overall_avg_price\")).show()\n",
        "    \n",
        "    print(\"\\n3Ô∏è‚É£ Total volume by symbol:\")\n",
        "    gold_df.groupBy(\"symbol\").agg(sum(\"total_volume\").alias(\"total_vol\")).orderBy(desc(\"total_vol\")).show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### ‚úÖ What we learned:\n",
        "1. **Gold Layer**: Aggregated, analytics-ready data\n",
        "2. **Windowed Aggregations**: Time-based metrics\n",
        "3. **Real-time Metrics**: Price, volume, volatility\n",
        "4. **Update Mode**: Update existing windows\n",
        "5. **Query Gold**: Real-time v√† historical analytics\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "- Lab 5: Unified batch + streaming (same code)\n",
        "- Lab 6: Query v√† time travel\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
