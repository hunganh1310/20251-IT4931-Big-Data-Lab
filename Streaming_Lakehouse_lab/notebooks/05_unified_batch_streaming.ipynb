{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: Unified Batch & Streaming - Same Code\n",
        "\n",
        "## ðŸŽ¯ **Learning Objectives:**\n",
        "- Write shared transformation functions\n",
        "- Apply same code cho batch vÃ  streaming\n",
        "- Process historical data vá»›i same logic\n",
        "- Write to same Iceberg tables\n",
        "- Compare results vÃ  performance\n",
        "\n",
        "## ðŸ“š **Key Concepts:**\n",
        "1. **Unified Code**: Same transformation cho batch vÃ  streaming\n",
        "2. **Code Reuse**: Write once, use for both\n",
        "3. **Same Storage**: CÃ¹ng Iceberg tables\n",
        "4. **Consistency**: Same logic â†’ same results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"UnifiedBatchStreaming\") \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "print(\"ðŸš€ Spark Session initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Shared Transformation Function\n",
        "\n",
        "### Key Idea:\n",
        "Viáº¿t 1 function dÃ¹ng cho cáº£ batch vÃ  streaming.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shared Transformation Function\n",
        "print(\"ðŸ”§ Exercise 1: Shared Transformation Function\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def process_stock_trades(df):\n",
        "    \"\"\"\n",
        "    Process stock trades - works for both batch and streaming!\n",
        "    Same logic, different triggers.\n",
        "    \"\"\"\n",
        "    return (df\n",
        "        .filter(col(\"price\") > 0)\n",
        "        .withColumn(\"total_value\", col(\"price\") * col(\"volume\"))\n",
        "        .withColumn(\"symbol\", upper(trim(col(\"symbol\"))))\n",
        "        .groupBy(\"symbol\", window(col(\"event_timestamp\"), \"1 minute\"))\n",
        "        .agg(\n",
        "            avg(\"price\").alias(\"avg_price\"),\n",
        "            sum(\"volume\").alias(\"total_volume\"),\n",
        "            sum(\"total_value\").alias(\"total_value\"),\n",
        "            count(\"*\").alias(\"trade_count\")\n",
        "        )\n",
        "        .select(\n",
        "            col(\"window.start\").alias(\"window_start\"),\n",
        "            col(\"window.end\").alias(\"window_end\"),\n",
        "            col(\"symbol\"),\n",
        "            col(\"avg_price\"),\n",
        "            col(\"total_volume\"),\n",
        "            col(\"total_value\"),\n",
        "            col(\"trade_count\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(\"âœ… Shared function defined!\")\n",
        "print(\"\\nðŸ’¡ This function works for:\")\n",
        "print(\"   âœ… Streaming DataFrames (readStream)\")\n",
        "print(\"   âœ… Batch DataFrames (read)\")\n",
        "print(\"   âœ… Same logic, same results!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Apply to Streaming\n",
        "\n",
        "### Streaming: Real-time processing tá»« Kafka\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply to Streaming\n",
        "print(\"ðŸ“¡ Exercise 2: Apply to Streaming\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Read from Kafka (streaming)\n",
        "kafka_stream = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"subscribe\", \"stock-trades\") \\\n",
        "    .option(\"startingOffsets\", \"earliest\") \\\n",
        "    .load()\n",
        "\n",
        "# Parse JSON (simplified - use actual schema)\n",
        "# ... parsing code ...\n",
        "\n",
        "# Apply shared function\n",
        "# stream_result = process_stock_trades(parsed_stream)\n",
        "\n",
        "print(\"âœ… Streaming pipeline with shared function!\")\n",
        "print(\"   Same function, streaming trigger\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Apply to Batch (Same Code!)\n",
        "\n",
        "### Batch: Historical data processing\n",
        "### Same function, same results!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply to Batch (Same Code!)\n",
        "print(\"ðŸ“¦ Exercise 3: Apply to Batch (Same Code!)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Read historical data (batch)\n",
        "# batch_df = spark.read.parquet(\"/historical/trades/\")\n",
        "\n",
        "# Apply SAME function!\n",
        "# batch_result = process_stock_trades(batch_df)\n",
        "\n",
        "print(\"âœ… Batch pipeline with SAME function!\")\n",
        "print(\"   Same function, batch trigger\")\n",
        "print(\"   Same logic â†’ Same results!\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Key Benefits:\")\n",
        "print(\"   âœ… Code reuse: Write once, use twice\")\n",
        "print(\"   âœ… Consistency: Same logic â†’ same results\")\n",
        "print(\"   âœ… Maintainability: Only 1 codebase to maintain\")\n",
        "print(\"   âœ… Testing: Test 1 function for both use cases\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### âœ… Key Takeaways:\n",
        "1. **Unified Code**: Same function cho batch vÃ  streaming\n",
        "2. **Code Reuse**: Write once, use for both\n",
        "3. **Consistency**: Same logic â†’ same results\n",
        "4. **Maintainability**: 1 codebase instead of 2\n",
        "5. **This is the power of Streaming Lakehouse!**\n",
        "\n",
        "### ðŸŽ¯ Why This Matters:\n",
        "- **Lambda**: Would need 2 separate functions\n",
        "- **Kappa**: Only streaming, no batch\n",
        "- **Streaming Lakehouse**: 1 function, both use cases âœ…\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
